<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>吴恩达深度学习（DeepLearning.ai）提及的论文 | IamXGW</title><meta name="keywords" content="深度学习,论文"><meta name="author" content="IamXGW"><meta name="copyright" content="IamXGW"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="看完视频后总结的课程中提及到的论文">
<meta property="og:type" content="article">
<meta property="og:title" content="吴恩达深度学习（DeepLearning.ai）提及的论文">
<meta property="og:url" content="http://example.com/posts/3232742656/index.html">
<meta property="og:site_name" content="IamXGW">
<meta property="og:description" content="看完视频后总结的课程中提及到的论文">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.4/img/postImg/paper_dl.png">
<meta property="article:published_time" content="2020-09-09T14:30:50.000Z">
<meta property="article:modified_time" content="2020-09-09T14:31:50.000Z">
<meta property="article:author" content="IamXGW">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.4/img/postImg/paper_dl.png"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.19/img/favicon.ico"><link rel="canonical" href="http://example.com/posts/3232742656/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8c61c88b53b633e29facebb0bb7d799b";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-177423460-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-177423460-1');
</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: IamXGW","link":"链接: ","source":"来源: IamXGW","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-09-09 22:31:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><link rel="stylesheet" href="/css/mouseStyle.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.19/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">58</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">47</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.4/img/postImg/paper_dl.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">IamXGW</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">吴恩达深度学习（DeepLearning.ai）提及的论文</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-09-09T14:30:50.000Z" title="发表于 2020-09-09 22:30:50">2020-09-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-09-09T14:31:50.000Z" title="更新于 2020-09-09 22:31:50">2020-09-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">935</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>5分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="第一课《神经网络和深度学习》"><a href="#第一课《神经网络和深度学习》" class="headerlink" title="第一课《神经网络和深度学习》"></a>第一课《神经网络和深度学习》</h3><p>无</p>
<h3 id="第二课《改善神经网络：超参调整，正则化和优化》"><a href="#第二课《改善神经网络：超参调整，正则化和优化》" class="headerlink" title="第二课《改善神经网络：超参调整，正则化和优化》"></a>第二课《改善神经网络：超参调整，正则化和优化》</h3><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Srivastava, Nitish, et al. “Dropout: a simple way to prevent neural networks from overfitting.” The journal of machine learning research 15.1 (2014): 1929-1958.</a></p>
</blockquote>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1412.6980.pdf">Kingma, Diederik P., and Jimmy Ba. “Adam: A method for stochastic optimization.” arXiv preprint arXiv:1412.6980 (2014).</a></p>
</blockquote>
<h3 id="第三课《结构化机器学习项目》"><a href="#第三课《结构化机器学习项目》" class="headerlink" title="第三课《结构化机器学习项目》"></a>第三课《结构化机器学习项目》</h3><p>无</p>
<h3 id="第四课《卷积神经网络CNN》"><a href="#第四课《卷积神经网络CNN》" class="headerlink" title="第四课《卷积神经网络CNN》"></a>第四课《卷积神经网络CNN》</h3><h4 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">LeCun, Yann, et al. “Gradient-based learning applied to document recognition.” Proceedings of the IEEE 86.11 (1998): 2278-2324.</a></p>
</blockquote>
<h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. “Imagenet classification with deep convolutional neural networks.” Advances in neural information processing systems. 2012.</a></p>
</blockquote>
<h4 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG-16"></a>VGG-16</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.1556.pdf">Simonyan, Karen, and Andrew Zisserman. “Very deep convolutional networks for large-scale image recognition.” arXiv preprint arXiv:1409.1556 (2014).</a></p>
</blockquote>
<h3 id="ps-Andrew-Ng-推荐阅读顺序：AlexNet-gt-VGG-gt-LeNet"><a href="#ps-Andrew-Ng-推荐阅读顺序：AlexNet-gt-VGG-gt-LeNet" class="headerlink" title="ps: Andrew Ng 推荐阅读顺序：AlexNet &gt; VGG &gt; LeNet"></a>ps: Andrew Ng 推荐阅读顺序：AlexNet &gt; VGG &gt; LeNet</h3><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">He, Kaiming, et al. “Deep residual learning for image recognition.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.</a></p>
</blockquote>
<h4 id="Network-in-network"><a href="#Network-in-network" class="headerlink" title="Network in network"></a>Network in network</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1312.4400.pdf">Lin, Min, Qiang Chen, and Shuicheng Yan. “Network in network.” arXiv preprint arXiv:1312.4400 (2013).</a></p>
</blockquote>
<h4 id="Inception-Network"><a href="#Inception-Network" class="headerlink" title="Inception Network"></a>Inception Network</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf">Szegedy, Christian, et al. “Going deeper with convolutions.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.</a></p>
</blockquote>
<h4 id="OverFeat"><a href="#OverFeat" class="headerlink" title="OverFeat"></a>OverFeat</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1312.6229">Sermanet, Pierre, et al. “Overfeat: Integrated recognition, localization and detection using convolutional networks.” arXiv preprint arXiv:1312.6229 (2013).</a></p>
</blockquote>
<h4 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf">Redmon, Joseph, et al. “You only look once: Unified, real-time object detection.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.</a></p>
</blockquote>
<h4 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf">Girshick, Ross, et al. “Rich feature hierarchies for accurate object detection and semantic segmentation.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2014.</a></p>
</blockquote>
<h4 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf">Girshick, Ross. “Fast r-cnn.” Proceedings of the IEEE international conference on computer vision. 2015.</a></p>
</blockquote>
<h4 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf">Ren, Shaoqing, et al. “Faster r-cnn: Towards real-time object detection with region proposal networks.” Advances in neural information processing systems. 2015.</a></p>
</blockquote>
<h4 id="Siamese-Network"><a href="#Siamese-Network" class="headerlink" title="Siamese Network"></a>Siamese Network</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf">Taigman, Yaniv, et al. “Deepface: Closing the gap to human-level performance in face verification.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2014.</a></p>
</blockquote>
<h4 id="FaceNet"><a href="#FaceNet" class="headerlink" title="FaceNet"></a>FaceNet</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf">Schroff, Florian, Dmitry Kalenichenko, and James Philbin. “Facenet: A unified embedding for face recognition and clustering.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.</a></p>
</blockquote>
<h4 id="Visualizing-and-understanding-convolutional-networks"><a href="#Visualizing-and-understanding-convolutional-networks" class="headerlink" title="Visualizing and understanding convolutional networks"></a>Visualizing and understanding convolutional networks</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1311.2901">Zeiler, Matthew D., and Rob Fergus. “Visualizing and understanding convolutional networks.” European conference on computer vision. Springer, Cham, 2014.</a></p>
</blockquote>
<h4 id="Neural-Style-Transfer"><a href="#Neural-Style-Transfer" class="headerlink" title="Neural Style Transfer"></a>Neural Style Transfer</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1508.06576">Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. “A neural algorithm of artistic style.” arXiv preprint arXiv:1508.06576 (2015).</a></p>
</blockquote>
<h3 id="第五课《序列模型》"><a href="#第五课《序列模型》" class="headerlink" title="第五课《序列模型》"></a>第五课《序列模型》</h3><h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.1259">Cho, Kyunghyun, et al. “On the properties of neural machine translation: Encoder-decoder approaches.” arXiv preprint arXiv:1409.1259 (2014).</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1412.3555">Chung, Junyoung, et al. “Empirical evaluation of gated recurrent neural networks on sequence modeling.” arXiv preprint arXiv:1412.3555 (2014).</a></p>
</blockquote>
<h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.676.4320&amp;rep=rep1&amp;type=pdf">Hochreiter, Sepp, and Jürgen Schmidhuber. “Long short-term memory.” Neural computation 9.8 (1997): 1735-1780.</a></p>
</blockquote>
<h4 id="t-SNE"><a href="#t-SNE" class="headerlink" title="t-SNE"></a>t-SNE</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">Maaten, Laurens van der, and Geoffrey Hinton. “Visualizing data using t-SNE.” Journal of machine learning research 9.Nov (2008): 2579-2605.</a></p>
</blockquote>
<h4 id="Analogy-reasoning"><a href="#Analogy-reasoning" class="headerlink" title="Analogy reasoning"></a>Analogy reasoning</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N13-1090.pdf">Mikolov, Tomas, Wen-tau Yih, and Geoffrey Zweig. “Linguistic regularities in continuous space word representations.” Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2013.</a></p>
</blockquote>
<h4 id="A-neural-probabilistic-language-model"><a href="#A-neural-probabilistic-language-model" class="headerlink" title="A neural probabilistic language model"></a>A neural probabilistic language model</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">Bengio, Yoshua, et al. “A neural probabilistic language model.” Journal of machine learning research 3.Feb (2003): 1137-1155.</a></p>
</blockquote>
<h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1301.3781.pdf%5D">Mikolov, Tomas, et al. “Efficient estimation of word representations in vector space.” arXiv preprint arXiv:1301.3781 (2013).</a></p>
</blockquote>
<h4 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Mikolov, Tomas, et al. “Distributed representations of words and phrases and their compositionality.” Advances in neural information processing systems. 2013.</a></p>
</blockquote>
<h4 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D14-1162.pdf">Pennington, Jeffrey, Richard Socher, and Christopher Manning. “Glove: Global vectors for word representation.” Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014.</a></p>
</blockquote>
<h4 id="Debiasing-word-embeddings"><a href="#Debiasing-word-embeddings" class="headerlink" title="Debiasing word embeddings"></a>Debiasing word embeddings</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf">Bolukbasi, Tolga, et al. “Man is to computer programmer as woman is to homemaker? debiasing word embeddings.” Advances in neural information processing systems. 2016.</a></p>
</blockquote>
<h4 id="Seq-2-Seq-amp-machine-translation"><a href="#Seq-2-Seq-amp-machine-translation" class="headerlink" title="Seq 2 Seq &amp; machine translation"></a>Seq 2 Seq &amp; machine translation</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.3215">Sutskever, I., O. Vinyals, and Q. V. Le. “Sequence to sequence learning with neural networks.” Advances in NIPS (2014).</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1406.1078">Cho, Kyunghyun, et al. “Learning phrase representations using RNN encoder-decoder for statistical machine translation.” arXiv preprint arXiv:1406.1078 (2014).</a></p>
</blockquote>
<h4 id="Image-captioning"><a href="#Image-captioning" class="headerlink" title="Image captioning"></a>Image captioning</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1412.6632">Mao, Junhua, et al. “Deep captioning with multimodal recurrent neural networks (m-rnn).” arXiv preprint arXiv:1412.6632 (2014).</a><br><a target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf">Vinyals, Oriol, et al. “Show and tell: A neural image caption generator.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf">Karpathy, Andrej, and Li Fei-Fei. “Deep visual-semantic alignments for generating image descriptions.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.</a></p>
</blockquote>
<h4 id="Bleu"><a href="#Bleu" class="headerlink" title="Bleu"></a>Bleu</h4><blockquote>
<p><a target="_blank" rel="noopener" href="http://www.mt-archive.info/00/IBM-2001-Papineni.pdf">Papineni, Kishore, et al. “BLEU: a method for automatic evaluation of machine translation.” Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 2002.</a></p>
</blockquote>
<h4 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.0473">Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. “Neural machine translation by jointly learning to align and translate.” arXiv preprint arXiv:1409.0473 (2014).</a></p>
<p><a target="_blank" rel="noopener" href="http://www.jmlr.org/proceedings/papers/v37/xuc15.pdf">Xu, Kelvin, et al. “Show, attend and tell: Neural image caption generation with visual attention.” International conference on machine learning. 2015.</a></p>
</blockquote>
<h4 id="CTC-cost"><a href="#CTC-cost" class="headerlink" title="CTC cost"></a>CTC cost</h4><blockquote>
<p><a target="_blank" rel="noopener" href="https://mediatum.ub.tum.de/doc/1292048/file.pdf">Graves, Alex, et al. “Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks.” Proceedings of the 23rd international conference on Machine learning. ACM, 2006.</a></p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">IamXGW</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/posts/3232742656/">http://example.com/posts/3232742656/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">IamXGW</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.4/img/postImg/paper_dl.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.7/img/alipay.jpeg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.7/img/alipay.jpeg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.7/img/wechatpay.jpeg" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.7/img/wechatpay.jpeg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/4214116711/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.10/img/postImg/Numpyyongfa.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Numpy常见用法</div></div></a></div><div class="next-post pull-right"><a href="/posts/3552669358/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.4/img/postImg/pythonQP.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python切片延展</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://cdn.jsdelivr.net/gh/IamXGW/CDN-for-xuguangwei.com@2.1.19/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">IamXGW</div><div class="author-info__description">万物之中，希望至美</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">58</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">47</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/IamXGW"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/IamXGW" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:iamxgw@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://twitter.com/IamXGW" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">本网站不定时更新！</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E8%AF%BE%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B"><span class="toc-number">1.</span> <span class="toc-text">第一课《神经网络和深度学习》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E8%AF%BE%E3%80%8A%E6%94%B9%E5%96%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E8%B0%83%E6%95%B4%EF%BC%8C%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8C%E4%BC%98%E5%8C%96%E3%80%8B"><span class="toc-number">2.</span> <span class="toc-text">第二课《改善神经网络：超参调整，正则化和优化》</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Dropout"><span class="toc-number">2.1.</span> <span class="toc-text">Dropout</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Adam"><span class="toc-number">2.2.</span> <span class="toc-text">Adam</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E8%AF%BE%E3%80%8A%E7%BB%93%E6%9E%84%E5%8C%96%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E3%80%8B"><span class="toc-number">3.</span> <span class="toc-text">第三课《结构化机器学习项目》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E8%AF%BE%E3%80%8A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E3%80%8B"><span class="toc-number">4.</span> <span class="toc-text">第四课《卷积神经网络CNN》</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LeNet-5"><span class="toc-number">4.1.</span> <span class="toc-text">LeNet-5</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AlexNet"><span class="toc-number">4.2.</span> <span class="toc-text">AlexNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#VGG-16"><span class="toc-number">4.3.</span> <span class="toc-text">VGG-16</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ps-Andrew-Ng-%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E9%A1%BA%E5%BA%8F%EF%BC%9AAlexNet-gt-VGG-gt-LeNet"><span class="toc-number">5.</span> <span class="toc-text">ps: Andrew Ng 推荐阅读顺序：AlexNet &gt; VGG &gt; LeNet</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ResNet"><span class="toc-number">5.1.</span> <span class="toc-text">ResNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Network-in-network"><span class="toc-number">5.2.</span> <span class="toc-text">Network in network</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Inception-Network"><span class="toc-number">5.3.</span> <span class="toc-text">Inception Network</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#OverFeat"><span class="toc-number">5.4.</span> <span class="toc-text">OverFeat</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YOLO"><span class="toc-number">5.5.</span> <span class="toc-text">YOLO</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#R-CNN"><span class="toc-number">5.6.</span> <span class="toc-text">R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Fast-R-CNN"><span class="toc-number">5.7.</span> <span class="toc-text">Fast R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Faster-R-CNN"><span class="toc-number">5.8.</span> <span class="toc-text">Faster R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Siamese-Network"><span class="toc-number">5.9.</span> <span class="toc-text">Siamese Network</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FaceNet"><span class="toc-number">5.10.</span> <span class="toc-text">FaceNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Visualizing-and-understanding-convolutional-networks"><span class="toc-number">5.11.</span> <span class="toc-text">Visualizing and understanding convolutional networks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Neural-Style-Transfer"><span class="toc-number">5.12.</span> <span class="toc-text">Neural Style Transfer</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E8%AF%BE%E3%80%8A%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E3%80%8B"><span class="toc-number">6.</span> <span class="toc-text">第五课《序列模型》</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#GRU"><span class="toc-number">6.1.</span> <span class="toc-text">GRU</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LSTM"><span class="toc-number">6.2.</span> <span class="toc-text">LSTM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#t-SNE"><span class="toc-number">6.3.</span> <span class="toc-text">t-SNE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Analogy-reasoning"><span class="toc-number">6.4.</span> <span class="toc-text">Analogy reasoning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#A-neural-probabilistic-language-model"><span class="toc-number">6.5.</span> <span class="toc-text">A neural probabilistic language model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Word2Vec"><span class="toc-number">6.6.</span> <span class="toc-text">Word2Vec</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Negative-Sampling"><span class="toc-number">6.7.</span> <span class="toc-text">Negative Sampling</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GloVe"><span class="toc-number">6.8.</span> <span class="toc-text">GloVe</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Debiasing-word-embeddings"><span class="toc-number">6.9.</span> <span class="toc-text">Debiasing word embeddings</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Seq-2-Seq-amp-machine-translation"><span class="toc-number">6.10.</span> <span class="toc-text">Seq 2 Seq &amp; machine translation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Image-captioning"><span class="toc-number">6.11.</span> <span class="toc-text">Image captioning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Bleu"><span class="toc-number">6.12.</span> <span class="toc-text">Bleu</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Attention"><span class="toc-number">6.13.</span> <span class="toc-text">Attention</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CTC-cost"><span class="toc-number">6.14.</span> <span class="toc-text">CTC cost</span></a></li></ol></li></ol></div></div></div></div></div></main><footer id="footer" style="background: #FAFAFA"><div id="footer-wrap"><div class="copyright">&copy; 2025  <i id="heartbeat" class="fa fas fa-heartbeat"></i> IamXGW | 框架 <a target="_blank" rel="noopener" href='https://hexo.io'>Hexo</a> | 主题 <a target="_blank" rel="noopener" href='https://github.com/jerryc127/hexo-theme-butterfly'>Butterfly</a></div></div><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></head><!--#footer-wrap--><!--  if theme.footer.owner.enable--><!--    - var now = new Date()--><!--    - var nowYear = now.getFullYear()--><!--    if theme.footer.owner.since && theme.footer.owner.since != nowYear--><!--      .copyright!= `&copy;${theme.footer.owner.since} - ${nowYear} By ${config.author}`--><!--    else--><!--      .copyright!= `&copy;${nowYear} By ${config.author}`--><!--  if theme.footer.copyright--><!--    .framework-info--><!--      span= _p('footer.framework') + ' '--><!--      a(href='https://hexo.io')= 'Hexo'--><!--      span.footer-separator |--><!--      span= _p('footer.theme') + ' '--><!--      a(href='https://github.com/jerryc127/hexo-theme-butterfly')= 'Butterfly'--><!--  if theme.footer.custom_text--><!--    .footer_custom_text!=`${theme.footer.custom_text}`--></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    $.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js', function () {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: 'd1671f644da78633eb55',
      clientSecret: 'b81e5b01a78c43fe47403ca9b7850bfdb9b771ff',
      repo: 'IamXGW.github.io',
      owner: 'IamXGW',
      admin: ['IamXGW'],
      id: '5c9e8c1dd957e8e9f0b94cda31754c7c',
      language: 'zh-CN',
      perPage: 9,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    $.getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js', initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>